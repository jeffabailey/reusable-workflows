name: Export Posts for Databricks

on:
  workflow_call:
    inputs:
      website_repository:
        required: true
        type: string
        description: "Repository containing the Hugo site (e.g. owner/repo)"
      debug:
        required: false
        type: boolean
        default: false
    secrets:
      aws_access_key_id:
        required: true
      aws_secret_access_key:
        required: true
      aws_s3_bucket:
        required: true
      access_token:
        required: true
        description: "Token to clone website_repository (if private)"

jobs:
  exportPosts:
    name: "Export Hugo content for Databricks"
    runs-on: ubuntu-latest

    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.aws_access_key_id }}
          aws-secret-access-key: ${{ secrets.aws_secret_access_key }}
          aws-region: us-east-1

      - name: Checkout reusable-workflows
        uses: actions/checkout@v4
        with:
          repository: jeffabailey/reusable-workflows
          token: ${{ secrets.access_token }}
          fetch-depth: 1
          path: reusable-workflows

      - name: Checkout website repository
        uses: actions/checkout@v4
        with:
          repository: ${{ github.repository }}
          fetch-depth: 1
          path: website

      - name: Set Default Git Branch
        run: git config --global init.defaultBranch master

      - name: Setup Hugo
        uses: peaceiris/actions-hugo@v2.6.0
        with:
          hugo-version: '0.154.5'
          extended: true

      - name: List all content with Hugo
        id: hugo-list
        working-directory: ./website/hugo
        run: |
          hugo list all > /tmp/hugo_list_all.csv || {
            echo "❌ hugo list all failed"
            exit 1
          }
          TOTAL_LINES=$(wc -l < /tmp/hugo_list_all.csv)
          echo "count=$TOTAL_LINES" >> "$GITHUB_OUTPUT"
          echo "✅ hugo list all produced $TOTAL_LINES lines"

      - name: Export to JSON Lines (Databricks-friendly)
        env:
          HUGO_LIST_FILE: /tmp/hugo_list_all.csv
          OUTPUT_FILE: posts_export.jsonl
        run: |
          python3 reusable-workflows/.github/workflows/generate-posts/export_posts.py

      - name: Upload to S3
        run: |
          if [ "${{ inputs.debug }}" = "true" ]; then
            aws s3 cp posts_export.jsonl s3://${{ secrets.aws_s3_bucket }}/posts_export.jsonl \
              --acl public-read \
              --cache-control max-age=3600,public
          else
            aws s3 cp posts_export.jsonl s3://${{ secrets.aws_s3_bucket }}/posts_export.jsonl \
              --acl public-read \
              --cache-control max-age=3600,public \
              --only-show-errors
          fi

      - name: Summary
        run: |
          echo "✅ Export complete"
          echo "   File: posts_export.jsonl ($(wc -l < posts_export.jsonl) records)"
          echo "   S3: s3://${{ secrets.aws_s3_bucket }}/posts_export.jsonl"
